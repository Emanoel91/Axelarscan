import streamlit as st
import pandas as pd
import requests
import plotly.graph_objects as go
import plotly.express as px
from datetime import datetime, time as dtime

# -------------------------------- Page config --------------------------------
st.set_page_config(page_title="Axelarscan", page_icon="https://axelarscan.io/logos/logo.png", layout="wide")
st.title("ğŸ“ˆ Interchain Chart")
st.info("ğŸ“ŠCharts initially display data for a default time range. Select a custom range to view results for your desired period.")
st.info("â³On-chain data retrieval may take a few moments. Please wait while the results load.")

# ------------------------------- Chains list ---------------------------------
chains = [
    "Avalanche","Axelarnet","Ethereum","Fantom","Moonbeam","Polygon","acre","agoric",
    "allora","arbitrum","archway","assetmantle","aura","babylon","base","berachain",
    "binance","bitsong","blast","c4e","carbon","celestia","celo","centrifuge","chihuahua",
    "comdex","cosmoshub","crescent","dymension","e-money","elys","evmos","fetch","filecoin",
    "flow","fraxtal","fxcore","haqq","hedera","hyperliquid","immutable","injective","ixo",
    "jackal","juno","kava","ki","kujira","lava","linea","mantle","mantra","migaloo",
    "neutron","nolus","ojo","optimism","osmosis","persistence","plume","provenance","rebus",
    "regen","saga","scroll","secret","secret-snip","sei","sommelier","stargaze","stellar",
    "stride","sui","teritori","terra","terra-2","umee","xion","xpla","xrpl","xrpl-evm","zigchain"
]

# ------------------------------- Top filters (not sidebar) -------------------
# Default dates: 2025-01-01 to 2026-01-01
default_start = datetime(2025, 1, 1).date()
default_end = datetime(2026, 1, 1).date()

filter_col = st.container()
with filter_col:
    c1, c2, c3, c4, c5 = st.columns([2,2,2,2,1.2])
    with c1:
        source_chain = st.selectbox("Source Chain", [""] + chains, index=0)
    with c2:
        destination_chain = st.selectbox("Destination Chain", [""] + chains, index=0)
    with c3:
        from_date = st.date_input("Start Date", value=default_start)
    with c4:
        to_date = st.date_input("End Date", value=default_end)
    with c5:
        timeframe = st.selectbox("Time Frame", ["day", "week", "month"], index=2)  # default = month

# --- Sidebar Footer Slightly Left-Aligned ---------------------------------------------------------------------
st.sidebar.markdown(
    """
    <style>
    .sidebar-footer {
        position: fixed;
        bottom: 20px;
        width: 250px;
        font-size: 13px;
        color: gray;
        margin-left: 5px; 
        text-align: left;  
    }
    .sidebar-footer img {
        width: 16px;
        height: 16px;
        vertical-align: middle;
        border-radius: 50%;
        margin-right: 5px;
    }
    .sidebar-footer a {
        color: gray;
        text-decoration: none;
    }
    </style>

    <div class="sidebar-footer">
        <div>
            <a href="https://x.com/axelar" target="_blank">
                <img src="https://img.cryptorank.io/coins/axelar1663924228506.png" alt="Axelar Logo">
                Powered by Axelar
            </a>
        </div>
        <div style="margin-top: 5px;">
            <a href="https://x.com/0xeman_raz" target="_blank">
                <img src="https://pbs.twimg.com/profile_images/1841479747332608000/bindDGZQ_400x400.jpg" alt="Eman Raz">
                Built by Eman Raz
            </a>
        </div>
    </div>
    """,
    unsafe_allow_html=True
)

# ------------------------------- Helper: timestamp parsing -------------------
def safe_parse_timestamp_series(series):
    """
    ÙˆØ±ÙˆØ¯ÛŒ Ù…ÛŒâ€ŒØªÙˆØ§Ù†Ø¯: Ø¹Ø¯Ø¯ Ø«Ø§Ù†ÛŒÙ‡ØŒ Ø¹Ø¯Ø¯ Ù…ÛŒÙ„ÛŒâ€ŒØ«Ø§Ù†ÛŒÙ‡ ÛŒØ§ Ø±Ø´ØªÙ‡ ISO Ø¨Ø§Ø´Ø¯.
    ØªØ§Ø¨Ø¹ ØªØ´Ø®ÛŒØµ Ù…ÛŒâ€ŒØ¯Ù‡Ø¯ Ùˆ pd.to_datetime Ø¨Ø§ unit Ù…Ù†Ø§Ø³Ø¨ ÙØ±Ø§Ø®ÙˆØ§Ù†ÛŒ Ù…ÛŒâ€ŒØ´ÙˆØ¯.
    Ø¯Ø± ØµÙˆØ±Øª Ø®Ø·Ø§ØŒ Ù…Ù‚Ø§Ø¯ÛŒØ± Ù†Ø§Ù…Ø¹ØªØ¨Ø± Ø¨Ù‡ NaT ØªØ¨Ø¯ÛŒÙ„ Ù…ÛŒâ€ŒØ´ÙˆÙ†Ø¯.
    """
    # Ø§Ú¯Ø± Ù‚Ø¨Ù„Ø§Ù‹ series Ø§Ø² Ù†ÙˆØ¹ datetime Ø¨Ø§Ø´Ø¯ØŒ Ø¨Ø±Ú¯Ø±Ø¯Ø§Ù†
    if pd.api.types.is_datetime64_any_dtype(series):
        return pd.to_datetime(series)

    # ØªÙ„Ø§Ø´ Ø¨Ø±Ø§ÛŒ ØªÙØ³ÛŒØ± Ø§Ø¹Ø¯Ø§Ø¯
    nums = pd.to_numeric(series, errors="coerce")
    if nums.notna().any():
        maxv = nums.max()
        # ØªØ´Ø®ÛŒØµ Ù…ÛŒÙ„ÛŒâ€ŒØ«Ø§Ù†ÛŒÙ‡ ÛŒØ§ Ø«Ø§Ù†ÛŒÙ‡ Ø¨Ø±Ø§Ø³Ø§Ø³ Ø¨Ø²Ø±Ú¯ÛŒ Ø¹Ø¯Ø¯
        if maxv > 1e11:
            unit = "ms"
        else:
            unit = "s"
        dt = pd.to_datetime(nums, unit=unit, errors="coerce")
        # Ø§Ú¯Ø± ØªÙ‚Ø±ÛŒØ¨Ø§Ù‹ Ù‡Ù…Ù‡ NaT Ø´Ø¯ØŒ Ø§Ø­ØªÙ…Ø§Ù„Ø§Ù‹ Ø±Ø´ØªÙ‡ ISO Ù‡Ø³ØªÙ†Ø¯ â€” ØªÙ„Ø§Ø´ Ø¯ÙˆØ¨Ø§Ø±Ù‡
        if dt.notna().sum() == 0:
            return pd.to_datetime(series, errors="coerce")
        return dt

    # Ø§Ú¯Ø± Ø¨Ù‡ ØµÙˆØ±Øª Ø±Ø´ØªÙ‡ ISO Ø¨Ø§Ø´Ø¯
    return pd.to_datetime(series, errors="coerce")

# ------------------------------- Build API params ----------------------------
base_url = "https://api.axelarscan.io/api/interchainChart"
params = {}
if source_chain:
    params["sourceChain"] = source_chain
if destination_chain:
    params["destinationChain"] = destination_chain

# convert from_date/to_date to unix (seconds)
if from_date:
    dt_from = datetime.combine(from_date, dtime.min)
    params["fromTime"] = int(dt_from.timestamp())
if to_date:
    dt_to = datetime.combine(to_date, dtime.max)
    params["toTime"] = int(dt_to.timestamp())

# ------------------------------- Fetch data ---------------------------------
with st.spinner("Fetching data from Axelar API..."):
    try:
        resp = requests.get(base_url, params=params, timeout=30)
        resp.raise_for_status()
        payload = resp.json()
        data = payload.get("data", [])
    except Exception as e:
        st.error(f"Error fetching data from API: {e}")
        data = []

# ------------------------------- DataFrame ---------------------------------
df = pd.DataFrame(data)

# If empty, create placeholder columns to avoid later crashes
if df.empty:
    st.warning("No data returned from API for the selected filters/range.")
    df = pd.DataFrame(columns=["timestamp","num_txs","volume","gmp_num_txs","gmp_volume","transfers_num_txs","transfers_volume"])

# --- IMPORTANT FIX:
# Overwrite (or create) single 'timestamp' column with parsed datetimes
# (this avoids creating duplicate column labels)
df["timestamp"] = safe_parse_timestamp_series(df.get("timestamp", pd.Series(dtype="object")))

# drop rows with invalid timestamp
df = df[~df["timestamp"].isna()].copy()

# ensure numeric columns exist (if missing from API, fill with zeros)
for col in ["num_txs","volume","gmp_num_txs","gmp_volume","transfers_num_txs","transfers_volume"]:
    if col not in df.columns:
        df[col] = 0

# Convert numeric columns properly
num_cols = ["num_txs","volume","gmp_num_txs","gmp_volume","transfers_num_txs","transfers_volume"]
df[num_cols] = df[num_cols].apply(pd.to_numeric, errors="coerce").fillna(0)

# Sort by timestamp and reset index
df = df.sort_values("timestamp").reset_index(drop=True)

# ------------------------------- Aggregation by timeframe -------------------
if timeframe == "day":
    df_agg = df.copy()
    df_agg["timestamp"] = pd.to_datetime(df_agg["timestamp"].dt.floor("D"))
    df_agg = df_agg.groupby("timestamp", as_index=False)[num_cols].sum()
elif timeframe == "week":
    df_agg = df.copy()
    df_agg = df_agg.set_index("timestamp").resample("W").sum(numeric_only=True).reset_index()
elif timeframe == "month":
    df_agg = df.copy()
    df_agg = df_agg.set_index("timestamp").resample("M").sum(numeric_only=True).reset_index()
else:
    df_agg = df.copy()

# If aggregation produced empty df (e.g. after filtering), create zeros to avoid plotting errors
if df_agg.empty:
    df_agg = pd.DataFrame({
        "timestamp": pd.to_datetime([]),
        "num_txs": pd.Series(dtype="int"),
        "volume": pd.Series(dtype="float"),
        "gmp_num_txs": pd.Series(dtype="int"),
        "gmp_volume": pd.Series(dtype="float"),
        "transfers_num_txs": pd.Series(dtype="int"),
        "transfers_volume": pd.Series(dtype="float"),
    })

# ------------------------------- KPIs --------------------------------------
total_txs = int(df_agg["num_txs"].sum()) if not df_agg.empty else 0
total_volume = float(df_agg["volume"].sum()) if not df_agg.empty else 0.0

k1, k2 = st.columns([1,1])
k1.metric("Total Number of Transfers", f"{total_txs:,}")
k2.metric("Total Volume of Transfers", f"{total_volume:,.2f}")

# ------------------------------- Chart 1: Number (bar) & Volume (line) -----
fig1 = go.Figure()

# Bar: Number of Transfers (Ø¢Ø¨ÛŒ)
fig1.add_bar(
    x=df_agg["timestamp"],
    y=df_agg["num_txs"],
    name="Number of Transfers",
    yaxis="y1",
    opacity=0.75,
    marker_color="#1f77b4"  # Ø¢Ø¨ÛŒ
)

# Line: Volume of Transfers (Ø³Ø¨Ø² Ù¾Ø±Ø±Ù†Ú¯)
fig1.add_trace(
    go.Scatter(
        x=df_agg["timestamp"],
        y=df_agg["volume"],
        name="Volume of Transfers",
        yaxis="y2",
        mode="lines+markers",
        line=dict(color="#006400", width=2),  # Ø³Ø¨Ø² Ù¾Ø±Ø±Ù†Ú¯
        marker=dict(color="#006400")
    )
)

fig1.update_layout(
    title="Volume & Number of Transfers Over Time",
    xaxis=dict(title="Date"),
    yaxis=dict(title="Txns count"),
    yaxis2=dict(title="$USD", overlaying="y", side="right"),
    legend=dict(
        orientation="h",   # Ø§ÙÙ‚ÛŒ
        yanchor="bottom",  # Ø§Ø² Ù¾Ø§ÛŒÛŒÙ† ØªØ±Ø§Ø² Ø´ÙˆØ¯
        y=1.05,            # Ú©Ù…ÛŒ Ø¨Ø§Ù„Ø§ÛŒ Ù†Ù…ÙˆØ¯Ø§Ø±
        xanchor="center",  # ØªØ±Ø§Ø² ÙˆØ³Ø·
        x=0.5              # Ø¯Ø± ÙˆØ³Ø· Ù…Ø­ÙˆØ± X
    ),
    height=480
)

st.plotly_chart(fig1, use_container_width=True)


# ------------------------------- Chart 2: Number by service (stacked) ------
fig2 = px.bar(df_agg, x="timestamp", y=["gmp_num_txs", "transfers_num_txs"], title="Number of Transfers by Service Over Time",
             labels={"value": "Txns count", "variable": "Service", "timestamp": "Date"}, color_discrete_map={"gmp_num_txs": "#fd9a57", "transfers_num_txs": "#85c2fb"})
fig2.for_each_trace(lambda t: t.update(name="GMP" if t.name == "gmp_num_txs" else "Token Transfer"))
fig2.update_layout(barmode="stack", height=450)
st.plotly_chart(fig2, use_container_width=True)

# ------------------------------- Chart 3: Volume by service (stacked) ------
fig3 = px.bar(df_agg, x="timestamp", y=["gmp_volume", "transfers_volume"], title="Volume of Transfers by Service Over Time ($USD)",
    labels={"value": "Volume ($USD)", "variable": "Service", "timestamp": "Date"}, color_discrete_map={"gmp_volume": "#fd9a57", "transfers_volume": "#85c2fb"})
fig3.for_each_trace(lambda t: t.update(name="GMP" if t.name == "gmp_volume" else "Token Transfer"))
fig3.update_layout(barmode="stack", height=450)
st.plotly_chart(fig3, use_container_width=True)

# ------------------------------- Donut charts --------------------------------
col_a, col_b = st.columns(2)

with col_a:
    vals_num = [df_agg["gmp_num_txs"].sum(), df_agg["transfers_num_txs"].sum()]
    fig4 = px.pie(names=["GMP", "Token Transfers"], values=vals_num, hole=0.55, title="Total Number of Transfers by Service", color_discrete_sequence=["#fd9a57", "#85c2fb"])
    st.plotly_chart(fig4, use_container_width=True)

with col_b:
    vals_vol = [df_agg["gmp_volume"].sum(), df_agg["transfers_volume"].sum()]
    fig5 = px.pie(names=["GMP", "Token Transfer"], values=vals_vol, hole=0.55, title="Total Volume of Transfers by Service ($USD)", color_discrete_sequence=["#fd9a57", "#85c2fb"])
    st.plotly_chart(fig5, use_container_width=True)

